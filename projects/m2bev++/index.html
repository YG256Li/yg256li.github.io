<!doctype html>
<html lang="en">
  <head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-156935549-3"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-156935549-3');
  </script>

    <style type="text/css">
      :root {
      --small-thumb-border-radius: 2px;
      --larger-thumb-border-radius: 3px;
    }

    html {
    font-size: 14px;
    line-height: 1.6;
    font-family: Inter, system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
    text-size-adjust: 100%;
    -ms-text-size-adjust: 100%;
    -webkit-text-size-adjust: 100%;
    }

    @media(min-width: 768px) {
    html {
      font-size: 16px;
    }
    }

    body {
      margin: 0px;
      padding: 0px;
    }

    .base-grid,
    .n-header,
    .n-byline,
    .n-title,
    .n-article,
    .n-footer {
      display: grid;
      justify-items: stretch;
      grid-template-columns: [screen-start] 8px [page-start kicker-start text-start gutter-start middle-start] 1fr 1fr 1fr 1fr 1fr 1fr 1fr 1fr [text-end page-end gutter-end kicker-end middle-end] 8px [screen-end];
      grid-column-gap: 8px;
    }

    .grid {
    display: grid;
    grid-column-gap: 8px;
    }

    @media(min-width: 768px) {
      .base-grid,
      .n-header,
      .n-byline,
      .n-title,
      .n-article,
      .n-footer {
          display: grid;
          justify-items: stretch;
          grid-template-columns: [screen-start] 1fr [page-start kicker-start middle-start text-start] 45px 45px 45px 45px 45px 45px 45px 45px [ kicker-end text-end gutter-start] 45px [middle-end] 45px [page-end gutter-end] 1fr [screen-end];
          grid-column-gap: 16px;
      }

      .grid {
          grid-column-gap: 16px;
      }
    }

    @media(min-width: 1000px) {
      .base-grid,
      .n-header,
      .n-byline,
      .n-title,
      .n-article,
      .n-footer {
          display: grid;
          justify-items: stretch;
          grid-template-columns: [screen-start] 1fr [page-start kicker-start] 50px [middle-start] 50px [text-start kicker-end] 50px 50px 50px 50px 50px 50px 50px 50px [text-end gutter-start] 50px [middle-end] 50px [page-end gutter-end] 1fr [screen-end];
          grid-column-gap: 16px;
      }

      .grid {
          grid-column-gap: 16px;
      }
    }

    @media (min-width: 1180px) {
      .base-grid,
      .n-header,
      .n-byline,
      .n-title,
      .n-article,
      .n-footer {
          display: grid;
          justify-items: stretch;
          grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
          grid-column-gap: 32px;
      }
      .grid {
          grid-column-gap: 32px;
      }

    }

    .base-grid {
    grid-column: screen;
    }

    /* default grid column assignments */
    .n-title > *  {
    grid-column: text;
    }

    .n-article > *  {
    grid-column: text;
    }

    .n-header {
      height: 0px;
    }

    .n-footer {
      height: 60px;
    }

    .n-title {
      padding: 4rem 0 1.5rem;
    }

    .l-page {
      grid-column: page;
    }

    .l-article {
      grid-column: text;
    }

    p {
    margin-top: 0;
    margin-bottom: 1em;
    }

    .pixelated {
      image-rendering: pixelated;
    }

    strong {
      font-weight: 600;
    }

    /*------------------------------------------------------------------*/
    /* title */
    .n-title h1 {
      font-family: "Barlow",system-ui,Arial,sans-serif;
      color:#082333;
      grid-column: text;
      font-size: 40px;
      font-weight: 700;
      line-height: 1.1em;
      margin: 0 0 0.5rem;
      text-align: center;
    }

    @media (min-width: 768px) {
      .n-title h1 {
          font-size: 50px;
      }
    }

    /*------------------------------------------------------------------*/
    /* article */
    .n-article {
      color: rgb(33, 40, 53);
      border-top: 1px solid rgba(0, 0, 0, 0.1);
      padding-top: 2rem;
    }

    .n-article h2 {
      contain: layout style;
      font-weight: 600;
      font-size: 24px;
      line-height: 1.25em;
      margin: 2rem 0 1.5rem 0;
      border-bottom: 1px solid rgba(0, 0, 0, 0.1);
      padding-bottom: 1rem;
    }

    @media (min-width: 768px) {
      .n-article {
          line-height: 1.7;
      }

      .n-article h2 {
          font-size: 36px;
      }
    }

    /*------------------------------------------------------------------*/
    /* byline */

    .n-byline {
    contain: style;
    overflow: hidden;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    font-size: 0.8rem;
    line-height: 1.8em;
    padding: 1.5rem 0;
    min-height: 1.8em;
    }

    .n-byline .byline {
    grid-column: text;
    }

    .byline {
      grid-template-columns: 1fr 1fr 1fr 1fr;
    }

    .grid {
      display: grid;
      grid-column-gap: 8px;
    }

    @media (min-width: 768px) {
    .grid {
      grid-column-gap: 16px;
    }
    }

    .n-byline p {
    margin: 0;
    }

    .n-byline h3 {
      font-size: 0.6rem;
      font-weight: 400;
      color: rgba(0, 0, 0, 0.5);
      margin: 0;
      text-transform: uppercase;
    }
    .n-byline .authors-affiliations {
    grid-column-end: span 2;
    grid-template-columns: 1fr 1fr;
    }

    /*------------------------------------------------------------------*/
    /* figures */
    .figure {
      margin-top: 1.5rem;
      margin-bottom: 1rem;
    }

    figcaption, .figcaption {
      color: rgba(0, 0, 0, 0.6);
      font-size: 12px;
      line-height: 1.5em;
    }

    ul.authors {
      list-style-type: none;
      padding: 0;
      margin: 0;
      text-align: center;
    }
    ul.authors li {
      padding: 0 0.5rem;
      display: inline-block;
    }

    ul.authors sup {
      color: rgb(126,126,126);
    }

    ul.authors.affiliations  {
      margin-top: 0.5rem;
    }

    ul.authors.affiliations li {
      color: rgb(126,126,126);
    }

    /* Download section columns.  This switches between two layouts::after
    - two columns on larger viewport sizes: side-by-side paper thumb and links
    - single column: no thumb
    */
    .download-section {
      display: grid;
      grid-template-areas: "links";
    }
    .download-section h4 {
      margin-left: 2.5rem;
      display: block;
    }
    .download-thumb {
      grid-area: thumb;
      display: none;
    }
    .download-links {
      grid-area: links;
    }
    img.dropshadow {
      box-shadow: 0 1px 10px rgba(0,0,0, 0.3);
    }

    @media(min-width: 1180px) {
      .download-section {
          display: grid;
          grid-template-areas: "thumb links";
      }
      .download-thumb {
          display: block;
      }
    }

    /* For BibTeX */
    pre {
      font-size: 0.9em;
      padding-left: 7px;
      padding-right: 7px;
      padding-top: 3px;
      padding-bottom: 3px;
      border-radius: 3px;
      background-color: rgb(235, 235, 235);
      overflow-x: auto;
    }

    /* video caption */

    .video {
      margin-top: 1.5rem;
      margin-bottom: 1.5rem;
    }

    .videocaption {
      display: flex;
      font-size: 16px;
      line-height: 1.5em;
      margin-bottom: 1rem;
      justify-content: center;
    }
      .disable-selection {
            user-select: none;
      -moz-user-select: none; /* Firefox */
        -ms-user-select: none; /* Internet Explorer */
    -khtml-user-select: none; /* KHTML browsers (e.g. Konqueror) */
    -webkit-user-select: none; /* Chrome, Safari, and Opera */
    -webkit-touch-callout: none; /* Disable Android and iOS callouts*/
    }

    .hidden {
      display: none;
    }

    h3.figtitle {
      margin-top: 0;
      margin-bottom: 0;
    }

    .fig-title-line {
      grid-template-columns: 2fr 0.75fr;
    }

    .fig-thumb-image-row {
      grid-template-columns: 1fr 1fr;
      grid-template-rows: 1fr;
    }

    .fig-thumb-image-row-item {
      width: 100%;
      min-height: auto;
      border-radius: var(--small-thumb-border-radius);
    }

    .fig-dataset-button {
      border-color: rgba(0,0,0,0);
      border-width: 1px;
      border-style: solid;
      cursor: pointer;
      opacity: 0.6;
    }

    .fig-dataset-button.active {
      border-color: rgba(0,0,0,0.7);
      border-width: 1px;
      border-style: solid;
      opacity: 1.0;
    }

    .grid {
      display: grid;
      grid-column-gap: 8px;
    }

    .fig-3-image-row {
      margin-top: 1em;
      grid-template-columns: 1fr 1.3fr 1fr;
      grid-template-rows: 1fr;
    }

    .fig-3-image-item {
      justify-self: center;
      align-self: center;
      width: 100%;
      border-radius: var(--larger-thumb-border-radius);
    }

    /*---------------------------------------------------------------------*/
    .fig-slider {
      grid-template-columns: auto 2fr;
      grid-template-rows: 1fr;
      margin-top: 1em;
      align-items: start;
      justify-content: center;
    }

    .fig-slider img.play_button {
      margin-right: 8px;
      cursor: pointer;
      justify-self: center;
    }
    .fig-slider svg {
      touch-action: none;
    }

    .fig-preload {
      display: none;
    }
    /*---------------------------------------------------------------------*/
    </style>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

    <!-- Other -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.4.2/handlebars.min.js"></script>

    <title>M<sup>2</sup>BEV++: Strong, Fast and Practical BEV Perception Baseline</title>
  </head>
  <body>

    <div style="overflow: hidden; background-color: #4466cc;">
      <div class="container">
      <a href=https://github.com/Sense-GVT/ style="float: left; color: black; text-align: center; padding: 12px 16px; text-decoration: none; font-size: 16px;"><img width="10%" src="https://avatars.githubusercontent.com/u/91599023?s=400&u=610631b531d5e4bd59255f6a3e697bf0fd335d91&v=4"></a> 
      <!-- <a href=https://github.com/Sense-GVT/ style="float: left; color: black; text-align: center; padding: 12px 16px; text-decoration: none; font-size: 16px;"></a> -->
      </div>
    </div>

    <!-- header -->
    <div class='jumbotron' style="background-color:#e6e9ec">
    <div class="container">

    <h1 class="text-center">M<sup>2</sup>BEV++: Strong, Fast and Practical BEV Perception Baseline</h1>
    <p class='text-center'>
        <a href="https://xieenze.github.io/">Enze Xie</a>     
    </p>
    <p class='text-center'>SenseTime, The University of Hong Kong</p>
    <p class='text-center'>Tech Report</p>
    <p class='text-center'>Official Code Page: <a href="https://github.com/Sense-GVT/M2BEV_V2/">https://github.com/Sense-GVT/M<sup>2</sup>BEV++</a></p>
    <p class='text-center'>Official Paper Release on: <a href='https://arxiv.org/abs/2204.05088' >arxiv link</a></p>
    <p class='text-center'>The performance of M<sup>2</sup>BEV++ on segmentation and tracking tasks will be updated before October 1st.</p>
    <p class='text-center'><img src='figs/demo.gif' class='img-fluid' style='width:1050px; border-radius:15px; padding:5px'></p>

   
    </div>
    </div>

    <div class="container">

      <p>
        Recently, the multi-camera Bird’s-Eye-View representation has attracted unprecedented attention for its impressive 3D perception capability and is promising for the next-generation feature representation paradigm in autonomous driving. However, most existing methods are still far from actual vehicle deployment due to high latency inference and resource occupation mainly caused by Transformer architecture and implicit/explicit depth estimation.
        In this technology report, we design a simple, efficient and direct framework, termed M<sup>2</sup>BEV++, following the principle of M<sup>2</sup>BEV. We empirically find the BEV representation can be sufficiently powerful without relying on Transformer and depth representation. As shown in Fig. 1, our improvement designs mainly contain three parts: 
        (1) We introduce a strong data augmentation strategy for both image and BEV space to avoid overfitting. 
        (2) We design a multi-frame feature fusion method, where the keyframe fuses three history frames at BEV space.
        (3) We optimize the view transformation with an accelerator to speed up the inference time. M<sup>2</sup>BEV++ establishes a new state-of-the-art XXX% NDS on the nuScenes validation set with ResNet-101 encoder and runs in real-time on the on-vehicle chips.
      </p>

    <hr/>
    <h4 class='text-center'>Main Idea</h4>
    <b>Two solutions for multi-camera AV perception.</b> 
    Top: Multiple task-specific networks operating on individual
    2D views cannot share features across tasks, and output
    view-specific results that need post-processing to fuse
    into the final, world-consistent output. Bottom: M^2BEV
    with a unified BEV feature representation, supporting
    <span style="color:#C71585">multi-view</span> <span style="color:#FF7F4F">multi-task</span> learning with a single network.

    <p class='text-center'><img src='figs/idea.png' class='img-fluid' style="border:0px solid #000000; border-radius: 15px;  width: 700px;"></p>

    <hr/>
    <h4 class='text-center'>Overview</h4>

    <b>The overall pipeline of M^2BEV.</b>  Given N images at timestamp T and corresponding
    intrinsic and extrinsic camera parameters as input, the encoder first extracts 2D features from the
    multi-view images, then the 2D features are unprojected to the 3D ego-car coordinate frame to
    generate a Bird’s-Eye View (BEV) feature representation. Finally, task-specific heads are adopted
    to predict 3D objects and maps.

    <p class='text-center'><img src='figs/pipeline.png' class='img-fluid' style="border:0px solid #000000; border-radius: 15px; width: 1000px;"></p> 

    <!-- <hr/>
    <h4 class='text-center'>Some Important Designs</h4>
    <p class='text-center'><img src='figs/design1.png' class='img-fluid' style="border:0px solid #000000; border-radius: 15px; width: 1000px;"></p>
    <p class='text-center'><img src='figs/design2.png' class='img-fluid' style="border:0px solid #000000; border-radius: 15px; width: 1000px;"></p> -->


    <hr/>
    <h4 class='text-center'>Results</h4>

    M^2BEV achieves state-of-the-art results on both 3D object detection and BEV segmentation on the nuScenes dataset. 
    Moreover, benefit from the unified BEV representation, M^2BEV is more runtime-efficient than both detection-only and segmentation-only methods.


    <p class='text-center'><img src='figs/det_perf.png' class='img-fluid' style="border:0px solid #000000; border-radius: 15px; width: 700px;"></p> 
    <p class='text-center'><img src='figs/segm_perf.png' class='img-fluid' style="border:0px solid #000000; border-radius: 15px; width: 700px;"></p> 

    
  

    <hr/>
    <h4 class='text-center'>M^2BEV Demo - Day</h4>

    M^2BEV is able to detect dense obstacles and segment maps accurately under complex road conditions.
    <div class="embed-responsive embed-responsive-16by9">
      <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/oOemWNjX7o8" style='display:block;' allowfullscreen></iframe>
    </div>
    <br>

    <hr/>
    <h4 class='text-center'>M^2BEV Demo - Night</h4>

    M^2BEV is also able to learn to see objects and environments clearly in the dark.

    <div class="embed-responsive embed-responsive-16by9">
      <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/UF4b45qTzLU" allowfullscreen></iframe>
    </div>
    <br>

    <hr/>
    <h4 class='text-center'> Citation </h4>
     <pre><code>@article{xie2022m,
      title={M<sup>2</sup>BEV++: Strong, Fast and Practical BEV Perception Baseline},
      author={},
      journal={},
      year={2022}
    }
  }</code></pre>

  <hr/>
  <h4 class='text-center'>Acknowledgement</h4>

  We would like to thank Wenwei Zhang (NTU), Tai Wang (CUHK) and Tianyuan Zhang (CMU) for the early codebase discussion.  



    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  </body>
</html>
